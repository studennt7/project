import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.seasonal import seasonal_decompose
from datetime import timedelta
import warnings
warnings.filterwarnings('ignore')

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö
@st.cache_data
def load_and_analyze_data(file):
    try:
        df = pd.read_excel(file)

        required_columns = ['–î–∞—Ç–∞', '–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂', '–í–∏–¥ –ø—Ä–æ–¥—É–∫—Ç–∞', '–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ', '–°—É–º–º–∞', '–¢–∏–ø –ø–æ–∫—É–ø–∞—Ç–µ–ª—è']
        missing_columns = [col for col in required_columns if col not in df.columns]

        if missing_columns:
            return f"–í —Ñ–∞–π–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing_columns)}", None

        df['–î–∞—Ç–∞'] = pd.to_datetime(df['–î–∞—Ç–∞'])
        df['–í—ã—Ä—É—á–∫–∞'] = df['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'] * df['–°—É–º–º–∞']

        return None, df

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}", None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è

def make_forecast(df, periods=30):
    try:
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –¥–Ω—è–º
        daily_data = df.groupby('–î–∞—Ç–∞').agg({'–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂': 'sum'}).reset_index()
        daily_data = daily_data.set_index('–î–∞—Ç–∞').asfreq('D').fillna(0)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏
        if len(daily_data) < 30:
            return None, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ (—Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 30 –¥–Ω–µ–π)"
        
        # –ê–Ω–∞–ª–∏–∑ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏
        decomposition = seasonal_decompose(daily_data['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'], period=7)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–æ–π–Ω–æ–µ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (Holt-Winters)
        model = ExponentialSmoothing(
            daily_data['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'],
            seasonal_periods=7,
            trend='add',
            seasonal='add',
            damped_trend=True
        ).fit()
        
        # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º
        forecast = model.forecast(periods)
        future_dates = pd.date_range(
            start=daily_data.index[-1] + timedelta(days=1),
            periods=periods
        )
        
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –ø—Ä–æ–≥–Ω–æ–∑–æ–º
        forecast_df = pd.DataFrame({
            '–î–∞—Ç–∞': future_dates,
            '–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂': forecast,
            '–¢–∏–ø': '–ü—Ä–æ–≥–Ω–æ–∑'
        })
        
        # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        actual_df = pd.DataFrame({
            '–î–∞—Ç–∞': daily_data.index,
            '–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂': daily_data['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'],
            '–¢–∏–ø': '–§–∞–∫—Ç'
        })
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ñ–∞–∫—Ç –∏ –ø—Ä–æ–≥–Ω–æ–∑
        combined_df = pd.concat([actual_df, forecast_df])
        
        return combined_df, None
        
    except Exception as e:
        return None, f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)}"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π

def generate_recommendations(df):
    recommendations = []

    try:
        daily_sales = df.groupby('–î–∞—Ç–∞')['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'].sum()
        decomposition = seasonal_decompose(daily_sales, period=7)

        if decomposition.seasonal.std() > (daily_sales.mean() * 0.1):
            recommendations.append(
                "üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∑–∞–º–µ—Ç–Ω–∞—è –Ω–µ–¥–µ–ª—å–Ω–∞—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–æ–¥–∞–∂–∞—Ö. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø–∞—Å—ã –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª —Å —É—á–µ—Ç–æ–º —ç—Ç–∏—Ö –∫–æ–ª–µ–±–∞–Ω–∏–π."
            )
    except:
        pass

    top_products = df.groupby('–í–∏–¥ –ø—Ä–æ–¥—É–∫—Ç–∞')['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'].sum().nlargest(3)
    if len(top_products) > 0:
        recommendations.append(
            f"üèÜ –¢–æ–ø-3 –ø—Ä–æ–¥—É–∫—Ç–∞ –ø–æ –æ–±—ä–µ–º—É –ø—Ä–æ–¥–∞–∂: {', '.join(top_products.index)}. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–≤–µ–ª–∏—á–∏—Ç—å –∏—Ö –Ω–∞–ª–∏—á–∏–µ –∏ –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–µ."
        )

    customer_stats = df.groupby('–¢–∏–ø –ø–æ–∫—É–ø–∞—Ç–µ–ª—è')['–í—ã—Ä—É—á–∫–∞'].agg(['sum', 'count'])
    if len(customer_stats) > 1:
        best_customer = customer_stats['sum'].idxmax()
        recommendations.append(
            f"üë• –ù–∞–∏–±–æ–ª—å—à—É—é –≤—ã—Ä—É—á–∫—É –ø—Ä–∏–Ω–æ—Å—è—Ç –ø–æ–∫—É–ø–∞—Ç–µ–ª–∏ —Ç–∏–ø–∞ '{best_customer}'. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –¥–ª—è –Ω–∏—Ö —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –ø—Ä–æ–≥—Ä–∞–º–º—É –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏."
        )

    location_stats = df.groupby('–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ')['–í—ã—Ä—É—á–∫–∞'].sum()
    if len(location_stats) > 1:
        best_location = location_stats.idxmax()
        worst_location = location_stats.idxmin()
        recommendations.append(
            f"üìç –õ–æ–∫–∞—Ü–∏—è '{best_location}' –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–∏–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –∞ '{worst_location}' - –Ω–∞–∏—Ö—É–¥—à–∏–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏–∑—É—á–∏—Ç—å –ø—Ä–∏—á–∏–Ω—ã —Ä–∞–∑–ª–∏—á–∏–π."
        )

    return recommendations if recommendations else ["üîé –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"]

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.set_page_config(page_title="Sales Smart Analytics", layout="wide")
st.title("üìä Sales Smart Analytics")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
with st.expander("üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ", expanded=True):
    st.markdown("""
    –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö. 
    –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏:
    - –î–∞—Ç–∞
    - –û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂ 
    - –í–∏–¥ –ø—Ä–æ–¥—É–∫—Ç–∞
    - –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ
    - –°—É–º–º–∞
    - –¢–∏–ø –ø–æ–∫—É–ø–∞—Ç–µ–ª—è
    """)

    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ Excel-—Ñ–∞–π–ª", type="xlsx", label_visibility="collapsed")

if uploaded_file is not None:
    error_msg, df = load_and_analyze_data(uploaded_file)

    if error_msg:
        st.error(error_msg)
    elif df is not None:
        total_sales = df['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'].sum()
        total_revenue = df['–í—ã—Ä—É—á–∫–∞'].sum()
        avg_price = df['–°—É–º–º–∞'].mean()
        unique_products = df['–í–∏–¥ –ø—Ä–æ–¥—É–∫—Ç–∞'].nunique()

        col1, col2, col3, col4 = st.columns(4)
        col1.metric("–û–±—â–∏–π –æ–±—ä–µ–º –ø—Ä–æ–¥–∞–∂", f"{total_sales:,.0f}")
        col2.metric("–û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞", f"{total_revenue:,.2f} —Ä—É–±.")
        col3.metric("–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞", f"{avg_price:,.2f} —Ä—É–±.")
        col4.metric("–í–∏–¥–æ–≤ –ø—Ä–æ–¥—É–∫—Ç–æ–≤", unique_products)

        st.subheader("–§–∏–ª—å—Ç—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        min_date = df['–î–∞—Ç–∞'].min().date()
        max_date = df['–î–∞—Ç–∞'].max().date()

        col1, col2 = st.columns(2)
        with col1:
            selected_dates = st.date_input("–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç", value=(min_date, max_date), min_value=min_date, max_value=max_date)

        with col2:
            selected_products = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–¥—É–∫—Ç—ã", options=df['–í–∏–¥ –ø—Ä–æ–¥—É–∫—Ç–∞'].unique(), default=df['–í–∏–¥ –ø—Ä–æ–¥—É–∫—Ç–∞'].unique())

        if len(selected_dates) == 2:
            start_date, end_date = selected_dates
            filtered_df = df[(df['–î–∞—Ç–∞'].dt.date >= start_date) & (df['–î–∞—Ç–∞'].dt.date <= end_date) & (df['–í–∏–¥ –ø—Ä–æ–¥—É–∫—Ç–∞'].isin(selected_products))]
        else:
            filtered_df = df[df['–í–∏–¥ –ø—Ä–æ–¥—É–∫—Ç–∞'].isin(selected_products)]

        tab1, tab2, tab3, tab4 = st.tabs(["–î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂", "–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–¥—É–∫—Ç–æ–≤", "–ê–Ω–∞–ª–∏–∑ –ª–æ–∫–∞—Ü–∏–π", "–ü—Ä–æ–≥–Ω–æ–∑ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"])

        with tab1:
            fig = px.line(
                filtered_df.groupby('–î–∞—Ç–∞')['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'].sum().reset_index(),
                x='–î–∞—Ç–∞',
                y='–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂',
                title='–î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂',
                labels={'–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂': '–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂', '–î–∞—Ç–∞': '–î–∞—Ç–∞'}
            )
            fig.update_xaxes(tickformat="%d %b", dtick="M15")
            fig.update_layout(hovermode="x unified")
            st.plotly_chart(fig, use_container_width=True)

        with tab2:
            col1, col2 = st.columns(2)
            with col1:
                product_sales = filtered_df.groupby('–í–∏–¥ –ø—Ä–æ–¥—É–∫—Ç–∞')['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'].sum().reset_index()
                fig = px.bar(product_sales, x='–í–∏–¥ –ø—Ä–æ–¥—É–∫—Ç–∞', y='–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂', title='–ü—Ä–æ–¥–∞–∂–∏ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º')
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                price_analysis = filtered_df.groupby('–í–∏–¥ –ø—Ä–æ–¥—É–∫—Ç–∞').agg(avg_price=('–°—É–º–º–∞', 'mean'), total_sales=('–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂', 'sum')).reset_index()
                fig = px.scatter(price_analysis, x='avg_price', y='total_sales', text='–í–∏–¥ –ø—Ä–æ–¥—É–∫—Ç–∞', title='–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ–±—ä–µ–º–∞ –æ—Ç —Ü–µ–Ω—ã', labels={'avg_price': '–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞', 'total_sales': '–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'})
                st.plotly_chart(fig, use_container_width=True)

        with tab3:
            col1, col2 = st.columns(2)
            with col1:
                location_sales = filtered_df.groupby('–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ')['–í—ã—Ä—É—á–∫–∞'].sum().reset_index()
                fig = px.pie(location_sales, names='–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ', values='–í—ã—Ä—É—á–∫–∞', title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã—Ä—É—á–∫–∏ –ø–æ –ª–æ–∫–∞—Ü–∏—è–º')
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                location_trend = filtered_df.groupby(['–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ', '–î–∞—Ç–∞'])['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'].sum().reset_index()
                fig = px.line(location_trend, x='–î–∞—Ç–∞', y='–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂', color='–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ', title='–î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂ –ø–æ –ª–æ–∫–∞—Ü–∏—è–º', labels={'–î–∞—Ç–∞': '–î–∞—Ç–∞', '–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂': '–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂', '–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ': '–õ–æ–∫–∞—Ü–∏—è'})
                fig.update_xaxes(tickformat="%d %b", dtick="M15", title="–î–∞—Ç–∞")
                fig.update_layout(hovermode="x unified", legend_title_text='–õ–æ–∫–∞—Ü–∏—è', margin=dict(t=40, b=40, l=0, r=0))
                st.plotly_chart(fig, use_container_width=True)

        with tab4:
    st.subheader("–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ –Ω–∞ 30 –¥–Ω–µ–π")
    forecast_df, forecast_error = make_forecast(filtered_df)

    if forecast_error:
        st.error(forecast_error)
    else:
        col1, col2 = st.columns(2)
        with col1:
            fig = px.line(
                forecast_df, 
                x='–î–∞—Ç–∞', 
                y='–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂', 
                color='–¢–∏–ø',
                title='–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º—ã–µ –ø—Ä–æ–¥–∞–∂–∏',
                line_dash='–¢–∏–ø',
                color_discrete_map={'–§–∞–∫—Ç': 'blue', '–ü—Ä–æ–≥–Ω–æ–∑': 'red'}
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª (–ø—Ä–∏–º–µ—Ä–Ω—ã–π)
            last_actual = forecast_df[forecast_df['–¢–∏–ø'] == '–§–∞–∫—Ç'].iloc[-1]['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂']
            fig.add_trace(go.Scatter(
                x=forecast_df[forecast_df['–¢–∏–ø'] == '–ü—Ä–æ–≥–Ω–æ–∑']['–î–∞—Ç–∞'],
                y=forecast_df[forecast_df['–¢–∏–ø'] == '–ü—Ä–æ–≥–Ω–æ–∑']['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'] * 1.2,
                fill=None,
                mode='lines',
                line=dict(width=0),
                showlegend=False
            ))
            
            fig.add_trace(go.Scatter(
                x=forecast_df[forecast_df['–¢–∏–ø'] == '–ü—Ä–æ–≥–Ω–æ–∑']['–î–∞—Ç–∞'],
                y=forecast_df[forecast_df['–¢–∏–ø'] == '–ü—Ä–æ–≥–Ω–æ–∑']['–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂'] * 0.8,
                fill='tonexty',
                mode='lines',
                line=dict(width=0),
                fillcolor='rgba(255,0,0,0.2)',
                name='–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª'
            ))
            
            fig.update_layout(
                xaxis_title='–î–∞—Ç–∞',
                yaxis_title='–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂',
                hovermode='x unified',
                legend_title_text='–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö'
            )
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            st.markdown("**–î–µ—Ç–∞–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞**")
            st.dataframe(
                forecast_df[forecast_df['–¢–∏–ø'] == '–ü—Ä–æ–≥–Ω–æ–∑'][['–î–∞—Ç–∞', '–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂']]
                .rename(columns={'–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂': '–ü—Ä–æ–≥–Ω–æ–∑ –æ–±—ä–µ–º–∞'})
                .style.format({'–ü—Ä–æ–≥–Ω–æ–∑ –æ–±—ä–µ–º–∞': '{:.1f}'}),
                hide_index=True
            )
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞
            st.markdown("**–ú–µ—Ç–æ–¥ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è**")
            st.write("""
            –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –º–µ—Ç–æ–¥ –•–æ–ª—å—Ç–∞-–í–∏–Ω—Ç–µ—Ä—Å–∞ —Å:
            - –£—á–µ—Ç–æ–º —Ç—Ä–µ–Ω–¥–∞
            - –£—á–µ—Ç–æ–º –Ω–µ–¥–µ–ª—å–Ω–æ–π —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏
            - –î–µ–º–ø—Ñ–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ç—Ä–µ–Ω–¥–∞ –¥–ª—è –±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
            """)

            st.subheader("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
            recommendations = generate_recommendations(filtered_df)
            for rec in recommendations:
                st.markdown(f"- {rec}")

        st.download_button(label="–°–∫–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", data=filtered_df.to_csv(index=False).encode('utf-8'), file_name='sales_analysis.csv', mime='text/csv')

